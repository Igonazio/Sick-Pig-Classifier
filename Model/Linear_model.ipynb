{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa8l_MFbX1z6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t23uvhAtX1z_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Resize\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split, Subset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnVgo10jh_D2",
        "outputId": "882e5356-a62f-4613-8a13-3083a5672b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file, header=None)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        image = image.float()\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "ZwyFxScMj7Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(all_data, test_portion = 0.3, seed = 0):\n",
        "  training_size = int((1 - test_portion) * len(all_data))\n",
        "  test_size = len(all_data) - training_size\n",
        "  training_indices, test_indices = random_split(\n",
        "                              range(len(all_data)), \n",
        "                              [training_size, test_size],\n",
        "                              generator=torch.Generator().manual_seed(seed))\n",
        "  training_data = Subset(all_data, training_indices)\n",
        "  test_data = Subset(all_data, test_indices)\n",
        "  return training_data, test_data"
      ],
      "metadata": {
        "id": "izp-z8EeEU8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = CustomImageDataset(\n",
        "    annotations_file=\"/content/drive/MyDrive/Ai builders/annotations_file.csv\", \n",
        "    img_dir=\"/content/drive/MyDrive/Ai builders/pig pics cleaned\", \n",
        "    transform=Resize(size=256), \n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "training_data, test_data = train_test_split(all_data)\n",
        "\n",
        "print(\"All data size: \" + str(len(all_data)))\n",
        "print(\"Training size: \" + str(len(training_data)) + \"\\tTest size: \" + str(len(test_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KcCdgfNJUPr",
        "outputId": "7ba63e6a-5939-4768-b836-39cd8ead5d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All data size: 511\n",
            "Training size: 357\tTest size: 154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2n7b-rpX10B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecfe1bbe-9d3b-4415-87da-6a28119b7edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 256, 256])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bScpoh5ZX10D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97745794-edb2-4698-80f2-424324a26f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=196608, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(256*256*3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jPGelD7X10E"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewGlKQ35X10F"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxBMN3LhX10F"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0KeRQYhX10G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ecad38-8517-4b82-db0b-ec0bc8ee457f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 8.870892  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss: 599577501630464.000000 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 541208627642368.000000  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss:     nan  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss:      nan \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki67FkRuX10H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685b2369-5c64-4350-dbfe-4cf2b08f529d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zudwtWqPX10H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839161ae-5f7c-4bee-c96b-fb261f9447ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YzIQTAlX10I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f7d0b1-f969-480e-d6f1-df2897e02fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"healthy\", Actual: \"sick\"\n"
          ]
        }
      ],
      "source": [
        "classes = [\n",
        "    \"healthy\",\n",
        "    \"sick\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x.view(1, -1))\n",
        "    \n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqjHWmIdRt6K",
        "outputId": "d7acaaa4-1875-4100-b96c-0096f115964c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = 0\n",
        "for i in range(len(test_data)):\n",
        "  model.eval()\n",
        "  x, y = test_data[i][0], test_data[i][1]\n",
        "  with torch.no_grad():\n",
        "    pred = model(x.view(1, -1))\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'{i}, Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "    if predicted == actual:\n",
        "      acc += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGanySwWQrnZ",
        "outputId": "e9fed11d-5bb9-4e1f-eb48-60aab5beb88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0, Predicted: \"healthy\", Actual: \"sick\"\n",
            "1, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "2, Predicted: \"healthy\", Actual: \"sick\"\n",
            "3, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "4, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "5, Predicted: \"sick\", Actual: \"healthy\"\n",
            "6, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "7, Predicted: \"healthy\", Actual: \"sick\"\n",
            "8, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "9, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "10, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "11, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "12, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "13, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "14, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "15, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "16, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "17, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "18, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "19, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "20, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "21, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "22, Predicted: \"healthy\", Actual: \"sick\"\n",
            "23, Predicted: \"healthy\", Actual: \"sick\"\n",
            "24, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "25, Predicted: \"healthy\", Actual: \"sick\"\n",
            "26, Predicted: \"healthy\", Actual: \"sick\"\n",
            "27, Predicted: \"healthy\", Actual: \"sick\"\n",
            "28, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "29, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "30, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "31, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "32, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "33, Predicted: \"healthy\", Actual: \"sick\"\n",
            "34, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "35, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "36, Predicted: \"sick\", Actual: \"healthy\"\n",
            "37, Predicted: \"sick\", Actual: \"sick\"\n",
            "38, Predicted: \"healthy\", Actual: \"sick\"\n",
            "39, Predicted: \"healthy\", Actual: \"sick\"\n",
            "40, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "41, Predicted: \"healthy\", Actual: \"sick\"\n",
            "42, Predicted: \"healthy\", Actual: \"sick\"\n",
            "43, Predicted: \"healthy\", Actual: \"sick\"\n",
            "44, Predicted: \"healthy\", Actual: \"sick\"\n",
            "45, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "46, Predicted: \"sick\", Actual: \"sick\"\n",
            "47, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "48, Predicted: \"healthy\", Actual: \"sick\"\n",
            "49, Predicted: \"healthy\", Actual: \"sick\"\n",
            "50, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "51, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "52, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "53, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "54, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "55, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "56, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "57, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "58, Predicted: \"healthy\", Actual: \"sick\"\n",
            "59, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "60, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "61, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "62, Predicted: \"healthy\", Actual: \"sick\"\n",
            "63, Predicted: \"healthy\", Actual: \"sick\"\n",
            "64, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "65, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "66, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "67, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "68, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "69, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "70, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "71, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "72, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "73, Predicted: \"healthy\", Actual: \"sick\"\n",
            "74, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "75, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "76, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "77, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "78, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "79, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "80, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "81, Predicted: \"sick\", Actual: \"healthy\"\n",
            "82, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "83, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "84, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "85, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "86, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "87, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "88, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "89, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "90, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "91, Predicted: \"healthy\", Actual: \"sick\"\n",
            "92, Predicted: \"healthy\", Actual: \"sick\"\n",
            "93, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "94, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "95, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "96, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "97, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "98, Predicted: \"healthy\", Actual: \"sick\"\n",
            "99, Predicted: \"healthy\", Actual: \"sick\"\n",
            "100, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "101, Predicted: \"healthy\", Actual: \"sick\"\n",
            "102, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "103, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "104, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "105, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "106, Predicted: \"healthy\", Actual: \"sick\"\n",
            "107, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "108, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "109, Predicted: \"healthy\", Actual: \"sick\"\n",
            "110, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "111, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "112, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "113, Predicted: \"healthy\", Actual: \"sick\"\n",
            "114, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "115, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "116, Predicted: \"healthy\", Actual: \"sick\"\n",
            "117, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "118, Predicted: \"healthy\", Actual: \"sick\"\n",
            "119, Predicted: \"healthy\", Actual: \"sick\"\n",
            "120, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "121, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "122, Predicted: \"healthy\", Actual: \"sick\"\n",
            "123, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "124, Predicted: \"healthy\", Actual: \"sick\"\n",
            "125, Predicted: \"healthy\", Actual: \"sick\"\n",
            "126, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "127, Predicted: \"sick\", Actual: \"healthy\"\n",
            "128, Predicted: \"healthy\", Actual: \"sick\"\n",
            "129, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "130, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "131, Predicted: \"healthy\", Actual: \"sick\"\n",
            "132, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "133, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "134, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "135, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "136, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "137, Predicted: \"sick\", Actual: \"sick\"\n",
            "138, Predicted: \"healthy\", Actual: \"sick\"\n",
            "139, Predicted: \"healthy\", Actual: \"sick\"\n",
            "140, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "141, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "142, Predicted: \"healthy\", Actual: \"sick\"\n",
            "143, Predicted: \"sick\", Actual: \"sick\"\n",
            "144, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "145, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "146, Predicted: \"healthy\", Actual: \"sick\"\n",
            "147, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "148, Predicted: \"healthy\", Actual: \"sick\"\n",
            "149, Predicted: \"healthy\", Actual: \"sick\"\n",
            "150, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "151, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "152, Predicted: \"healthy\", Actual: \"healthy\"\n",
            "153, Predicted: \"healthy\", Actual: \"sick\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "name": "Linear model",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}