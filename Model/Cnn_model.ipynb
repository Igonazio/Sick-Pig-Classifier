{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cnn model",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmU-MnkaTwd7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLZ4WKHbTwd-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Resize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, Subset"
      ],
      "metadata": {
        "id": "dTmm30w8fuAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "607-vduaSiHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file, header=None)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        image = image.float()\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "        "
      ],
      "metadata": {
        "id": "u6Ad4tAigMwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(all_data, test_portion = 0.3, seed = 0):\n",
        "  training_size = int((1 - test_portion) * len(all_data))\n",
        "  test_size = len(all_data) - training_size\n",
        "  training_indices, test_indices = random_split(\n",
        "                              range(len(all_data)), \n",
        "                              [training_size, test_size],\n",
        "                              generator=torch.Generator().manual_seed(seed))\n",
        "  training_data = Subset(all_data, training_indices)\n",
        "  test_data = Subset(all_data, test_indices)\n",
        "  return training_data, test_data"
      ],
      "metadata": {
        "id": "izp-z8EeEU8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qpqnoGGak0c",
        "outputId": "02031148-eea1-4578-b574-058c1f4d8cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv7-RGLQTwd-",
        "outputId": "4436d005-3808-432b-ee64-6a345e00e35f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All data size: 511\n",
            "Training size: 357\tTest size: 154\n"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets.\n",
        "\n",
        "all_data = CustomImageDataset(\n",
        "    annotations_file=\"/content/drive/MyDrive/Ai builders/annotations_file.csv\", \n",
        "    img_dir=\"/content/drive/MyDrive/Ai builders/pig pics cleaned\", \n",
        "    transform=Resize(size=128), \n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "training_data, test_data = train_test_split(all_data)\n",
        "\n",
        "print(\"All data size: \" + str(len(all_data)))\n",
        "print(\"Training size: \" + str(len(training_data)) + \"\\tTest size: \" + str(len(test_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v3GQjD8Twd_",
        "outputId": "2354663b-fb85-46bc-86cc-02b4db55f407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 128, 128])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWhlkVIv-P3w",
        "outputId": "92583258-6007-4e4e-b59d-63817dab9a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    (7): Linear(in_features=9216, out_features=128, bias=True)\n",
            "    (8): Dropout(p=0.5, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define convoluational NN model\n",
        "\n",
        "#################################\n",
        "# Input \n",
        "# 128 x 128 x 3\n",
        "\n",
        "# A convolutional layer with 32 filters of size 5x5\n",
        "# 124 x 124 x 32\n",
        "\n",
        "# A ReLU nonlinearity\n",
        "\n",
        "# A max pooling layer with size 3x3 (ceil_mode=False)\n",
        "# 41 x 41 x 32\n",
        "\n",
        "# A convolutional layer with 64 filters of size 5x5\n",
        "# 37 x 37 x 64\n",
        "\n",
        "# A ReLU nonlinearity\n",
        "\n",
        "# A max pooling layer with size 3x3 (ceil_mode=False)\n",
        "# 12 x 12 x 64\n",
        "\n",
        "# A flatten layer\n",
        "# 9216 x 1\n",
        "\n",
        "# A fully connected layer with 128 neurons\n",
        "\n",
        "# A dropout layer with drop probability 0.5\n",
        "\n",
        "# A fully-connected layer with 2 neuron\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "              nn.Conv2d(3, 32, (5, 5)),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d((3, 3)),\n",
        "              nn.Conv2d(32, 64, (5, 5)),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d((3, 3)),\n",
        "              nn.Flatten(),\n",
        "              nn.Linear(9216, 128),\n",
        "              nn.Dropout(0.5),\n",
        "              nn.Linear(128, 2)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I80ze8yoTweA"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmPzjzc2TweB"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLa83sR5TweB"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            # print(f\"X.Shape: {X.shape}\")\n",
        "            pred = model(X)\n",
        "            # print(f\"pred: {pred}\")\n",
        "            # print(f\"pred shape: {pred.shape}\")\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qaqq1hhGgcEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_gwHBNSTweC",
        "outputId": "fca04cbd-8cfc-4176-d803-4fa5b0173fad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 6.867768  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 44.8%, Avg loss: 0.692855 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.749365  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 45.5%, Avg loss: 0.688125 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.721584  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 51.3%, Avg loss: 0.686310 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.695873  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 52.6%, Avg loss: 0.681224 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.732331  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 67.5%, Avg loss: 0.646953 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.732001  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 66.9%, Avg loss: 0.658671 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.665917  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 70.1%, Avg loss: 0.607232 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.621725  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 64.9%, Avg loss: 0.645143 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.621831  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 52.6%, Avg loss: 0.687042 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.624737  [    0/  357]\n",
            "Test Error: \n",
            " Accuracy: 63.0%, Avg loss: 0.618497 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYjbyyFcTweC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fcb6a36-e245-4c75-9618-5c9709ed17f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"resnet_50_b_model_128.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fLNXKF7Ngrki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYQj6lyFYDF4",
        "outputId": "916d011c-776f-461f-8f5f-f83c4b4913b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.73      0.73       107\n",
            "           1       0.40      0.40      0.40        47\n",
            "\n",
            "    accuracy                           0.63       154\n",
            "   macro avg       0.57      0.57      0.57       154\n",
            "weighted avg       0.63      0.63      0.63       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "def get_incorrect_predictions(model, test_dataloader):\n",
        "  out1 = []\n",
        "  out2 = []\n",
        "  \n",
        "  for i in range(len(test_data)):\n",
        "    model.eval()\n",
        "    x, y = test_data[i][0], test_data[i][1]\n",
        "    \n",
        "    # Turn it into 4D tensor [N, C, H, W] just like in dataloader\n",
        "    x = x.unsqueeze(0)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      \n",
        "      pred = model(x)\n",
        "      predicted, actual = pred[0].argmax(0), y\n",
        "   \n",
        "      out1.append(predicted.item())\n",
        "      out2.append(y)\n",
        "       \n",
        "  return out1, out2\n",
        "y_true,y_pred = get_incorrect_predictions(model,test_dataloader)\n",
        "print(classification_report(y_true,y_pred))\n"
      ]
    }
  ]
}